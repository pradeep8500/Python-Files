{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                name  id  \\\n",
      "0   Coffee coco butter ylang ylang soap 125gm (Copy)   4   \n",
      "1        OW' Real Tulsi Green Tea + Saffron -25 bags   5   \n",
      "2      Aum Fresh Sundarikalp Tea 50 gm (25 Tea Bags)  10   \n",
      "3                  Baby natural laundry wash 1000 ml  11   \n",
      "4            Kairali Amruthotharam Kashayam (200 ml)  12   \n",
      "5         Aum Fresh Nidrakar Tea 50 gm (25 Tea Bags)  13   \n",
      "6           Aum Fresh Memory Tea 50 gm (25 Tea Bags)  14   \n",
      "7           Kairali Balaguluchyedi Kashayam (200 ml)  15   \n",
      "8       Aum Fresh Gas Relief Tea 50 gm (25 Tea Bags)  16   \n",
      "9         Aum Fresh Vajikaran Tea 50gm (25 Tea Bags)  17   \n",
      "10         Kairali Cheriya Rasnadi Kashayam (200 ml)  18   \n",
      "\n",
      "                                              sku  \n",
      "0                                        SKU 9480  \n",
      "1                                       SKU 11067  \n",
      "2   Aum Fresh Sundarikalp Tea 50 gm (25 Tea Bags)  \n",
      "3               Baby natural laundry wash 1000 ml  \n",
      "4         Kairali Amruthotharam Kashayam (200 ml)  \n",
      "5      Aum Fresh Nidrakar Tea 50 gm (25 Tea Bags)  \n",
      "6        Aum Fresh Memory Tea 50 gm (25 Tea Bags)  \n",
      "7        Kairali Balaguluchyedi Kashayam (200 ml)  \n",
      "8    Aum Fresh Gas Relief Tea 50 gm (25 Tea Bags)  \n",
      "9      Aum Fresh Vajikaran Tea 50gm (25 Tea Bags)  \n",
      "10      Kairali Cheriya Rasnadi Kashayam (200 ml)  \n",
      "['1000', '125gm', '200', '25', '50', '50gm', 'amruthotharam', 'aum', 'baby', 'bags', 'balaguluchyedi', 'butter', 'cheriya', 'coco', 'coffee', 'copy', 'fresh', 'gas', 'gm', 'green', 'kairali', 'kashayam', 'laundry', 'memory', 'ml', 'natural', 'nidrakar', 'ow', 'rasnadi', 'real', 'relief', 'saffron', 'soap', 'sundarikalp', 'tea', 'tulsi', 'vajikaran', 'wash', 'ylang']\n",
      "['1000', '11067', '200', '25', '50', '50gm', '9480', 'amruthotharam', 'aum', 'baby', 'bags', 'balaguluchyedi', 'cheriya', 'fresh', 'gas', 'gm', 'kairali', 'kashayam', 'laundry', 'memory', 'ml', 'natural', 'nidrakar', 'rasnadi', 'relief', 'sku', 'sundarikalp', 'tea', 'vajikaran', 'wash']\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "ds = pd.read_csv(\"AR_all.csv\")\n",
    "ds=ds[0:11]\n",
    "print(ds[[ 'name','id','sku']])\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), min_df=1, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(ds['name'])\n",
    "print(tf.get_feature_names())\n",
    "#print(tfidf_matrix)\n",
    "#print(ds['name'][0:5])\n",
    "tf1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), min_df=1, stop_words='english')\n",
    "tfidf_matrix1 = tf1.fit_transform(ds['sku'])\n",
    "print(tf1.get_feature_names())\n",
    "#print(tfidf_matrix1)\n",
    "\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_similarities1 = linear_kernel(tfidf_matrix1, tfidf_matrix1)\n",
    "#print(cosine_similarities)\n",
    "results = {}\n",
    "results1 = {}\n",
    "\n",
    "for idx, row in ds.iterrows():\n",
    "    #print('',)\n",
    "    similar_indices = cosine_similarities[idx].argsort()[::-1]\n",
    "   # print(similar_indices)\n",
    "    similar_items = [(cosine_similarities[idx][i], ds['id'][i]) for i in similar_indices]\n",
    "    similar_indices1 = cosine_similarities1[idx].argsort()[::-1]\n",
    "    #print(similar_indices1)\n",
    "    similar_items1 = [(cosine_similarities1[idx][i], ds['id'][i]) for i in similar_indices1]\n",
    "    #print(similar_items1)\n",
    "    # First item is the item itself, so remove it.\n",
    "    # Each dictionary entry is like: [(1,2), (3,4)], with each tuple being (score, item_id)\n",
    "    results[row['id']] = similar_items[1:]\n",
    "    results1[row['id']] = similar_items1[1:]  \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending 10 products similar to Aum Fresh Sundarikalp Tea 50 gm (25 Tea Bags)...\n",
      "-------\n",
      "[(0.7936077671566899, 14), (0.7936077671566899, 13), (0.7225395819469875, 16), (0.601304817994677, 17), (0.0, 18), (0.0, 15), (0.0, 12), (0.0, 11), (0.0, 5), (0.0, 4)]\n",
      "[14, 13, 16, 17, 5, 18, 15, 12, 11, 4]\n",
      "Recommended: Aum Fresh Memory Tea 50 gm (25 Tea Bags) (score:0.775864421749223)\n",
      "Recommended: Aum Fresh Nidrakar Tea 50 gm (25 Tea Bags) (score:0.775864421749223)\n",
      "Recommended: Aum Fresh Gas Relief Tea 50 gm (25 Tea Bags) (score:0.7012470979466564)\n",
      "Recommended: Aum Fresh Vajikaran Tea 50gm (25 Tea Bags) (score:0.5674002443191339)\n",
      "[14, 13, 16, 17, 18, 15, 12, 11, 5, 4]\n",
      "Recommended: Aum Fresh Memory Tea 50 gm (25 Tea Bags) (score:0.7936077671566899)\n",
      "Recommended: Aum Fresh Nidrakar Tea 50 gm (25 Tea Bags) (score:0.7936077671566899)\n",
      "Recommended: Aum Fresh Gas Relief Tea 50 gm (25 Tea Bags) (score:0.7225395819469875)\n",
      "Recommended: Aum Fresh Vajikaran Tea 50gm (25 Tea Bags) (score:0.601304817994677)\n"
     ]
    }
   ],
   "source": [
    "def item(id):\n",
    "    return ds.loc[ds['id'] == id]['name'].tolist()[0].split(' - ')[0]\n",
    "\n",
    "# Just reads the results out of the dictionary. No real logic here.\n",
    "def recommend(item_id, num):\n",
    "    print(\"Recommending \" + str(num) + \" products similar to \" + item(item_id) + \"...\")\n",
    "    print(\"-------\")\n",
    "    recs = results[item_id][:num]\n",
    "    recs1 = results1[item_id][:num]\n",
    "    print(recs1)\n",
    "    l=[]\n",
    "    l1=[]\n",
    "    #Sprint(recs)\n",
    "    for i in recs:\n",
    "        l.append(i[1])\n",
    "    print(l)     \n",
    "    for rec in recs:\n",
    "       if rec[0]>(0.50/2):\n",
    "         print(\"Recommended: \" + item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")\n",
    "    for i in recs1:\n",
    "        l1.append(i[1])\n",
    "    print(l1)     \n",
    "    for rec in recs1:\n",
    "       if rec[0]>0.50:\n",
    "         print(\"Recommended: \" + item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")    \n",
    "\n",
    "# Just plug in any item id here (1-500), and the number of recommendations you want (1-99)\n",
    "# You can get a list of valid item IDs by evaluating the variable 'ds', or a few are listed below\n",
    "\n",
    "recommend(item_id=10, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
